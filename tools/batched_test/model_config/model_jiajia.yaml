- name: "example-model"
  model_path: "/path/to/example-model"
  tp: 99
  pp: 99
  dp: 99
  distributed_executor_backend: "ray"  # default
  gpu_memory_utilization: 0.9  # default
  swap_space: 16  # default
  max_model_len: 4096  # default

  # Optional extra arguments for vllm serve command
  # won't overwrite the default args
  # won't check the validity of these args
  extra_args:
    -mtp:
    --chat-template: chat_template/tool_chat_template_deepseekr1.jinja
  extra_env:
    EXAMPLE_ENV_VAR: "value"

- name: "DeepSeek-V2-Lite"
  model_path: "/mnt/share/models/DeepSeek/DeepSeek-V2-Lite"
  tp: 2
  pp: 1
  dp: 1
  extra_args:
    --chat-template: chat_template/tool_chat_template_deepseekr1.jinja
  extra_env:
    MACA_QUEUE_SCHEDULE_POLICY: 1

- name: "Qwen3-4B"
  model_path: "/mnt/share/models/Qwen/Qwen3-4B"
  tp: 2
  pp: 1
  dp: 1
  extra_args:

- name: "Qwen3-8B"
  model_path: "/mnt/share/models/Qwen/Qwen3-8B"
  tp: 4
  pp: 1
  dp: 1
  distributed_executor_backend: "mp" # for test mp and ray both work
  extra_args: 

# - name: "Qwen3-14B"
#   model_path: "/mnt/share/models/Qwen/Qwen3-14B"
#   tp: 4
#   pp: 1
#   dp: 1
#   distributed_executor_backend: "mp"
#   extra_args: 

# - name: "Qwen3-235B-A22B"
#   model_path: "/mnt/share/models/Qwen/Qwen3-235B-A22B"
#   tp: 8
#   pp: 2
#   dp: 1
#   extra_args: 
  
# - name: "Qwen3-30B-A3B"
#   model_path: "/mnt/share/models/Qwen/Qwen3-30B-A3B"
#   tp: 2
#   pp: 1
#   dp: 1
#   extra_args: 